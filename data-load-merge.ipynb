{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d078c688",
   "metadata": {},
   "source": [
    "### **Import Library**\n",
    "Kita mulai dengan mengimpor semua library yang diperlukan untuk memproses dan menggabungkan data:\n",
    "- `os` & `glob`: untuk membaca file dari folder\n",
    "- `pandas` & `numpy`: untuk manipulasi data\n",
    "- `statistics.mode`: untuk menghitung modus (nilai paling sering muncul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a131cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang dibutuhkan\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4528d25",
   "metadata": {},
   "source": [
    "### **Membaca dan Menggabungkan Data CO2**\n",
    "\n",
    "Kode ini secara sistematis melakukan beberapa tugas penting:\n",
    "1.  **Menemukan File:** Menggunakan `glob` untuk secara otomatis menemukan semua file dengan ekstensi `.csv` di dalam folder data mentah CO2.\n",
    "2.  **Membaca & Menggabungkan:** Membaca setiap file CSV yang ditemukan ke dalam DataFrame, lalu langsung menggabungkannya menjadi satu DataFrame tunggal (`df_co2`) menggunakan `pd.concat`.\n",
    "3.  **Memilih Kolom:** Hanya menyimpan kolom-kolom yang relevan, yaitu `timestamp` dan `co2`.\n",
    "4.  **Konversi Tipe Data:** Memastikan kolom `timestamp` diubah menjadi format `datetime` dan kolom `co2` menjadi format numerik (`float` atau `int`).\n",
    "\n",
    "**Tujuan:**\n",
    "Untuk mengonsolidasikan semua data CO2 yang mungkin terfragmentasi dalam banyak file (misalnya, satu file per hari) menjadi satu dataset tunggal yang siap untuk diolah lebih lanjut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3923d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan path ke folder data CO2\n",
    "folder_path_co2 = 'dataset/data-raw/co2'\n",
    "all_csv_files = glob.glob(os.path.join(folder_path_co2, \"*.csv\"))\n",
    "\n",
    "# Gabungkan semua file CSV\n",
    "df_co2 = pd.concat([pd.read_csv(f) for f in all_csv_files], ignore_index=True)\n",
    "df_co2 = df_co2[['timestamp', 'co2']]\n",
    "\n",
    "# Konversi tipe data\n",
    "df_co2['timestamp'] = pd.to_datetime(df_co2['timestamp'], errors='coerce')\n",
    "df_co2['co2'] = pd.to_numeric(df_co2['co2'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d64a65",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:** \n",
    "- Terbentuknya sebuah DataFrame tunggal bernama `df_co2` yang berisi seluruh data CO2 dari semua file sumber.\n",
    "-   Penggunaan `glob` membuat proses ini **otomatis dan skalabel**. Jika ada file data baru yang ditambahkan ke folder, kode ini akan langsung menyertakannya pada eksekusi berikutnya tanpa perlu diubah.\n",
    "-   Penggunaan parameter **`errors='coerce'`** saat konversi tipe data adalah langkah \"jaga-jaga\". Jika ada baris data yang formatnya salah atau rusak di file asli, proses tidak akan berhenti karena error. Sebaliknya, data yang salah itu akan diubah menjadi `NaN` (Not a Number) atau `NaT` (Not a Time), yang bisa kita tangani secara sistematis di tahap pembersihan selanjutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3db30",
   "metadata": {},
   "source": [
    "### **Sampling dan Data CO2**\n",
    "\n",
    "Prosesnya terdiri dari empat bagian:\n",
    "1.  **Standardisasi Waktu:** Membuat kolom baru `minute` dengan membulatkan `timestamp` ke bawah ke awal menit terdekat (`.floor('min')`). Ini mengelompokkan semua pembacaan dalam satu menit ke stempel waktu yang sama.\n",
    "2.  **Agregasi per Menit (Resampling):** Mengelompokkan data berdasarkan kolom `minute` yang baru, lalu untuk setiap menit, mengambil nilai **modus (mode)** atau nilai yang paling sering muncul dari pembacaan CO2.\n",
    "3.  **Membuat Indeks Waktu Penuh:** Membuat sebuah rentang waktu yang ideal dan lengkap (`full_minutes`) dari awal hingga akhir data, dengan interval persis setiap satu menit tanpa ada yang terlewat.\n",
    "4.  **Penggabungan (Merge):** Melakukan `left merge` antara indeks waktu yang lengkap dengan data CO2 yang sudah di-resample.\n",
    "\n",
    "**Tujuan:**\n",
    "Untuk mengatasi dua masalah umum pada data sensor:\n",
    "-   Adanya beberapa pembacaan dalam satu menit.\n",
    "-   Adanya jeda waktu di mana tidak ada pembacaan sama sekali.\n",
    "Dengan proses ini, kita memastikan kita memiliki satu nilai representatif untuk setiap menit dan struktur data yang konsisten (satu baris per menit), yang sangat penting untuk penggabungan dengan data lain dan untuk analisis deret waktu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff61d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulatkan waktu ke menit terdekat\n",
    "df_co2['minute'] = df_co2['timestamp'].dt.floor('min')\n",
    "\n",
    "# Sampling modus CO2 per menit\n",
    "minute_co2 = df_co2.groupby('minute')['co2'].agg(\n",
    "    lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    ").reset_index()\n",
    "\n",
    "# Lengkapi semua menit agar tidak ada yang hilang\n",
    "full_minutes = pd.date_range(\n",
    "    start=df_co2['minute'].min().floor('D'),\n",
    "    end=df_co2['minute'].max().ceil('D') - pd.Timedelta(minutes=1),\n",
    "    freq='1min'\n",
    ")\n",
    "full_minutes_df = pd.DataFrame({'minute': full_minutes})\n",
    "co2_sampled = full_minutes_df.merge(minute_co2, on='minute', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef90a4",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Terbentuknya DataFrame `co2_sampled` di mana setiap baris mewakili satu menit yang unik dan berurutan. Jika pada satu menit tertentu tidak ada data CO2 asli, nilainya akan menjadi `NaN` (kosong).\n",
    "-   Keputusan untuk menggunakan **modus (`.mode()`)** daripada rata-rata (`.mean()`) adalah pilihan yang dirasa tepat. Jika dalam satu menit ada beberapa pembacaan dan salah satunya adalah *noise* atau nilai yang sangat aneh, modus tidak akan terpengaruh, sementara rata-rata akan menjadi tidak akurat. Ini membuat prosesnya lebih kuat (robust) terhadap data pencilan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd154bc8",
   "metadata": {},
   "source": [
    "### **Menyimpan Data CO2 Hasil Sampling**\n",
    "\n",
    "DataFrame `co2_sampled` yang berisi data CO2 yang sudah rapi dan berurutan per menit, disimpan ke dalam sebuah file CSV baru.\n",
    "\n",
    "**Tujuan:**\n",
    "Langkah ini berfungsi sebagai **checkpoint** atau titik simpan yang sangat penting. Proses resampling pada langkah sebelumnya bisa jadi memakan waktu jika datanya sangat besar. Dengan menyimpan hasilnya ke dalam file, kita mengamankan progres kita. Jika terjadi error di langkah-langkah selanjutnya, kita bisa memulai kembali dari titik ini dengan hanya memuat file `co2_per_minute.csv`, tanpa harus mengulang seluruh proses resampling dari awal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3333e3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2 per menit disimpan di: dataset/data-clean/co2_per_minute.csv\n"
     ]
    }
   ],
   "source": [
    "# Simpan hasil sampling CO2\n",
    "output_co2_path = 'dataset/data-clean/co2_per_minute.csv'\n",
    "co2_sampled.to_csv(output_co2_path, index=False)\n",
    "print(f\"CO2 per menit disimpan di: {output_co2_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69a19a",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Berhasil dibuatnya file `dataset/data-clean/co2_per_minute.csv`.\n",
    "-   Kita sekarang memiliki file data CO2 yang bersih dan terstruktur secara independen dari file-file mentah aslinya. Ini membuat alur kerja kita lebih modular dan efisien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba3457",
   "metadata": {},
   "source": [
    "### **Memuat dan Membersihkan Data Cuaca**\n",
    "\n",
    "Serupa dengan penanganan data CO2, kode ini melakukan beberapa tugas untuk data cuaca:\n",
    "1.  **Mencari dan Membaca File:** Menggunakan `os.listdir` dan sebuah *loop* untuk membaca semua file CSV dari folder data mentah cuaca.\n",
    "2.  **Menggabungkan:** Menyusun semua data cuaca dari file-file terpisah menjadi satu DataFrame tunggal (`df_weather`) menggunakan `pd.concat`.\n",
    "3.  **Membuang Kolom:** Menghapus kolom-kolom yang tidak akan digunakan dalam analisis ini (`direction`, `angle`, `wind_speed`) dengan metode `.drop()`.\n",
    "4.  **Konversi Tipe Data:** Memastikan kolom `timestamp` diubah menjadi format `datetime` yang benar.\n",
    "\n",
    "**Tujuan:**\n",
    "Untuk mengonsolidasikan dan membersihkan semua data cuaca, sehingga siap untuk digabungkan dengan data CO2 yang telah kita proses sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5b3b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_weather = 'dataset/data-raw/cuaca'\n",
    "file_list_weather = sorted(os.listdir(folder_path_weather))\n",
    "\n",
    "df_list_weather = []\n",
    "for file in file_list_weather:\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(folder_path_weather, file))\n",
    "        df_list_weather.append(df)\n",
    "\n",
    "df_weather = pd.concat(df_list_weather, ignore_index=True)\n",
    "df_weather = df_weather.drop(['direction', 'angle', 'wind_speed'], axis=1)  # Hapus kolom tak diperlukan\n",
    "df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fd886",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Terbentuknya sebuah DataFrame tunggal bernama `df_weather` yang berisi semua data cuaca yang relevan (`temperature`, `humidity`, `rainfall`, `pyrano`) dengan stempel waktu yang sudah diformat dengan benar.\n",
    "-   Tindakan menghapus beberapa kolom cuaca merupakan bentuk awal dari **seleksi fitur (feature selection)**. Ini menunjukkan keputusan sadar bahwa fitur-fitur tersebut dianggap tidak terlalu relevan untuk tujuan akhir proyek, sehingga model dan analisis kita bisa lebih fokus pada variabel yang paling penting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33d38f",
   "metadata": {},
   "source": [
    "### **Memfilter dan Merapikan Data Cuaca**\n",
    "\n",
    "Kode ini melakukan dua tugas penting pada data cuaca:\n",
    "1.  **Memfilter Berdasarkan Tanggal:** Pertama, data cuaca disaring untuk hanya menyertakan data dalam rentang tanggal tertentu (dari 24 April hingga 7 Mei 2025).\n",
    "2.  **Regularisasi Waktu:** Sama seperti pada data CO2, kita membuat sebuah rentang waktu (`full_range`) yang lengkap untuk setiap menit dalam periode tersebut, lalu menggabungkannya (`left merge`) dengan data cuaca yang sudah difilter.\n",
    "\n",
    "**Tujuan:**\n",
    "\n",
    "-   **Scoping:** Memastikan kita hanya bekerja dengan data dari periode yang relevan, kemungkinan untuk menyamakannya dengan ketersediaan data CO2.\n",
    "-   **Alignment:** Memaksa data cuaca untuk memiliki struktur waktu yang **identik** dengan data CO2 yang telah kita proses sebelumnya (satu baris per menit, tanpa ada jeda). Ini adalah persiapan krusial untuk langkah penggabungan akhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b70acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2025-04-24'\n",
    "end_date = '2025-05-07'\n",
    "\n",
    "# Filter tanggal\n",
    "filtered_weather = df_weather[(df_weather['timestamp'] >= start_date) & (df_weather['timestamp'] <= end_date)].copy()\n",
    "\n",
    "# Lengkapi waktu setiap menit\n",
    "full_range = pd.date_range(start=start_date + ' 00:00:00', end=end_date + ' 23:59:00', freq='min')\n",
    "full_weather_df = pd.DataFrame({'timestamp': full_range})\n",
    "\n",
    "weather_sampled = pd.merge(full_weather_df, filtered_weather, on='timestamp', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54293fd8",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Terbentuknya DataFrame `weather_sampled` yang berisi data cuaca hanya untuk rentang tanggal yang ditentukan dan memiliki struktur waktu per menit yang sempurna. Baris di mana tidak ada data cuaca asli akan berisi nilai `NaN`.\n",
    "-   Dengan menyamakan \"grid\" waktu untuk kedua dataset (CO2 dan cuaca) sebelum menggabungkannya, kita memastikan integritas data. Proses penggabungan akhir akan jauh lebih bersih dan akurat karena kedua dataset sudah \"berbicara dalam bahasa waktu yang sama\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab52b9",
   "metadata": {},
   "source": [
    "### **Menyimpan Data Cuaca Hasil Olahan (Checkpoint)**\n",
    "\n",
    "DataFrame `weather_sampled` yang berisi data cuaca yang sudah difilter dan dirapikan per menit, disimpan ke dalam sebuah file CSV baru.\n",
    "\n",
    "**Tujuan:**\n",
    "Sama seperti pada data CO2, langkah ini berfungsi sebagai **checkpoint**. Kita menyimpan hasil pengolahan data cuaca yang sudah bersih ke dalam file terpisah. Ini membuat alur kerja kita menjadi sangat **modular**. Jika kita perlu melakukan penggabungan ulang nanti, kita bisa langsung memuat file ini dan file CO2 yang sudah diproses, tanpa perlu mengulang semua langkah pembersihan dari awal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ec4a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuaca per menit disimpan di: dataset/data-clean/cuaca_per_menit.csv\n"
     ]
    }
   ],
   "source": [
    "output_weather_path = 'dataset/data-clean/cuaca_per_menit.csv'\n",
    "weather_sampled.to_csv(output_weather_path, index=False)\n",
    "print(f\"Cuaca per menit disimpan di: {output_weather_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050df4a1",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Berhasil dibuatnya file `dataset/data-clean/cuaca_per_menit.csv`.\n",
    "-   Pada titik ini, kita telah berhasil memproses dua sumber data yang berbeda (CO2 dan cuaca) secara terpisah dan menyimpannya dalam format yang bersih dan terstruktur. Keduanya kini siap untuk \"dipertemukan\" pada langkah penggabungan final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59714382",
   "metadata": {},
   "source": [
    "### **Menggabungkan Data CO2 dan Cuaca yang Telah Diproses**\n",
    "\n",
    "1.  **Memuat Data Checkpoint:** Kita memuat kembali dua file CSV bersih yang telah kita buat sebelumnya: `co2_per_minute.csv` dan `cuaca_per_menit.csv`.\n",
    "2.  **Konversi Waktu:** Memastikan kolom waktu di kedua DataFrame (`minute` dan `timestamp`) berformat `datetime`.\n",
    "3.  **Penggabungan (`Merge`):** Menggabungkan kedua DataFrame menjadi satu (`merged_df`) menggunakan `pd.merge`. Kunci penggabungannya adalah kolom waktu yang sudah kita samakan strukturnya pada langkah-langkah sebelumnya.\n",
    "4.  **Finalisasi Kolom:** Membersihkan kolom-kolom sisa dari proses merge, yaitu menghapus satu kolom waktu yang duplikat dan mengganti nama kolom waktu utama menjadi `timestamp`.\n",
    "\n",
    "**Tujuan:**\n",
    "Untuk menciptakan satu **master dataset** yang tunggal. Setiap baris dalam dataset final ini akan berisi informasi lengkap dan pembacaan CO2 beserta kondisi cuaca yang terjadi pada menit yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03eda0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ulang data yang telah disampling\n",
    "co2_df = pd.read_csv('dataset/data-clean/co2_per_minute.csv')\n",
    "cuaca_df = pd.read_csv('dataset/data-clean/cuaca_per_menit.csv')\n",
    "\n",
    "# Konversi waktu agar bisa digabung\n",
    "co2_df['minute'] = pd.to_datetime(co2_df['minute'])\n",
    "cuaca_df['timestamp'] = pd.to_datetime(cuaca_df['timestamp'])\n",
    "\n",
    "# Gabungkan berdasarkan waktu\n",
    "merged_df = pd.merge(co2_df, cuaca_df, left_on='minute', right_on='timestamp', how='left')\n",
    "\n",
    "# Finalisasi\n",
    "merged_df.drop(columns=['timestamp'], inplace=True)\n",
    "merged_df.rename(columns={'minute': 'timestamp'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbf809",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Terbentuknya DataFrame `merged_df` yang merupakan produk akhir dari notebook ini, siap untuk disimpan dan digunakan untuk analisis selanjutnya.\n",
    "-   Keberhasilan dan kesederhanaan dari `pd.merge` di tahap ini adalah buah dari kerja keras pada langkah-langkah sebelumnya. Karena kita sudah melakukan **regularisasi dan alignment data** pada kedua dataset, proses penggabungan akhir menjadi sangat lugas dan akurat. Ini menunjukkan pentingnya menyiapkan setiap sumber data secara terpisah sebelum menggabungkannya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c9291",
   "metadata": {},
   "source": [
    "### **Menyimpan Data Gabungan Final**\n",
    "\n",
    "Ini adalah langkah final dari notebook ini. DataFrame `merged_df` yang berisi gabungan lengkap data CO2 dan cuaca disimpan ke dalam sebuah file CSV baru, yaitu `data_output_collecting.csv`. Parameter `index=False` digunakan agar indeks DataFrame tidak ikut ditulis ke dalam file.\n",
    "\n",
    "**Tujuan:**\n",
    "Untuk menghasilkan **artefak** atau *output* akhir dari tahap pengumpulan dan penggabungan data. File CSV ini akan menjadi **sumber data tunggal (single source of truth)** untuk semua notebook dan analisis di tahap selanjutnya (EDA dan *modeling*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c49abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data gabungan berhasil disimpan di: dataset/data-clean/data_output_collecting.csv\n"
     ]
    }
   ],
   "source": [
    "output_merged_path = 'dataset/data-clean/data_output_collecting.csv'\n",
    "merged_df.to_csv(output_merged_path, index=False)\n",
    "print(f\"Data gabungan berhasil disimpan di: {output_merged_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4290a6",
   "metadata": {},
   "source": [
    "**Hasil dan Insight:**\n",
    "-   Berhasil dibuatnya file `dataset/data-clean/data_output_collecting.csv`.\n",
    "-   Dengan disimpannya file ini, maka seluruh proses penggabungan data telah selesai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
